{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import sleep\n",
    "import random \n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use beatufull soup to get the number of articles per year\n",
    "One of the parameters for NYTimes API request is 'page'. Page number has to be less than 200 => Need to break down by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(1985,2019,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995,\n",
       "       1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006,\n",
       "       2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
       "       2018])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that inouts a year in the url and return the number of articles with a gives search query\n",
    "def num_of_pages(year):\n",
    "    url = f'https://www.nytimes.com/search/gun%20control/newest/{year}0101/{year}1231'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    search_page = response.text\n",
    "    soup = BeautifulSoup(search_page,\"html5lib\")\n",
    "    search_result = soup.find_all(class_='SearchForm-searchStatus--2Z3Tw')\n",
    "    search_result_str = str(search_result)\n",
    "    num_of_articles = re.match(r'.*Showing\\s(\\d,*\\d+)\\sresults.*',search_result_str).group(1)\n",
    "    num = int(num_of_articles.replace(',',''))\n",
    "    return(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985 :  279\n",
      "1986 :  243\n",
      "1987 :  217\n",
      "1988 :  340\n",
      "1989 :  357\n",
      "1990 :  377\n",
      "1991 :  412\n",
      "1992 :  468\n",
      "1993 :  539\n",
      "1994 :  618\n",
      "1995 :  431\n",
      "1996 :  477\n",
      "1997 :  369\n",
      "1998 :  416\n",
      "1999 :  828\n",
      "2000 :  1009\n",
      "2001 :  537\n",
      "2002 :  513\n",
      "2003 :  445\n",
      "2004 :  498\n",
      "2005 :  349\n",
      "2006 :  463\n",
      "2007 :  700\n",
      "2008 :  478\n",
      "2009 :  517\n",
      "2010 :  462\n",
      "2011 :  631\n",
      "2012 :  836\n",
      "2013 :  1418\n",
      "2014 :  678\n",
      "2015 :  817\n",
      "2016 :  1226\n",
      "2017 :  635\n",
      "2018 :  761\n"
     ]
    }
   ],
   "source": [
    "news_per_year = defaultdict()\n",
    "for year in years:\n",
    "    news_per_year[year]=num_of_pages(year)\n",
    "    print(year, ': ', num_of_pages(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to NYTimes API to get article meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ROOT = 'https://api.nytimes.com/svc/search/v2/articlesearch.json'\n",
    "\n",
    "API_SIGNUP_PAGE = 'http://developer.nytimes.com/docs/reference/keys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys that stoppped working\n",
    "# '05faa13dbd9f43f2baaa8cfb77fdbdf6'\n",
    "# 'e4a266caf4924515a7fb9b093584f54b'\n",
    "# 'a5bea43a4bc94a9ca93987ac86239055'\n",
    "# '26a1d65efbed44a788dd16e4c41c6b11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys = ['574c1decf6e34ee884d48718ac9420ee']\n",
    "keys= ['fbdb0bf2114c49a4af9d5a810f5ad0d5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from 01/01/1985 to date there are 19,294 articles that came up for 'gun control' search term.\n",
    "it means i have to iterate through 1930 pages to collect the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that calls NYTimes API and returns a json object with sesarch page results \n",
    "# Note: returns meta data about 10 articles (1 search page)\n",
    "def create_request(start_date, end_date, page_num):\n",
    "    s = len(keys)-1\n",
    "    API_KEY = keys[random.randint(0,s)]\n",
    "    resp = requests.get(API_ROOT, params={\n",
    "        'api-key': API_KEY,\n",
    "        'q': \"gun control\",\n",
    "        'begin_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'sort': \"newest\",\n",
    "        'page': page_num})\n",
    "    return(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-03a2d0312997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20130101'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'20131231'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-fc174b2a3bbc>\u001b[0m in \u001b[0;36mcreate_request\u001b[0;34m(start_date, end_date, page_num)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mAPI_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     resp = requests.get(API_ROOT, params={\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'api-key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAPI_KEY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "test = create_request('20130101', '20131231', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4e1243bd22c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that takes json output and parses data from it\n",
    "# this will return article URLs for further scraping of articles' text\n",
    "def parse_search_res(json_file):\n",
    "    news = []\n",
    "    for i in json_file['response']['docs']:   \n",
    "        dic = {}\n",
    "        dic['id'] = i['_id']\n",
    "        dic['headline'] = i['headline']['main'].encode(\"utf8\")\n",
    "        dic['date'] = i['pub_date'][0:10]\n",
    "        dic['score'] = i['score']\n",
    "        if i['snippet'] is not None:\n",
    "            dic['snippet'] = i['snippet'].encode(\"utf8\")\n",
    "        if 'source' in i:\n",
    "            dic['source'] = i['source']\n",
    "        if 'type_of_material' in i:\n",
    "            dic['type'] = i['type_of_material']\n",
    "        dic['url'] = i['web_url']\n",
    "        dic['word_count'] = i['word_count']\n",
    "        news.append(dic)\n",
    "    return(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that takes the number of article during publication year \n",
    "# and splits them into chunks of 500 artciles. This is done becasue API is limiting number of calls and breaks \n",
    "# def find_slices(v):\n",
    "#     if v<=500:\n",
    "#         slices = [math.ceil(v/10)]\n",
    "#         return([math.ceil(v/10)])\n",
    "#     else:\n",
    "#         slices = []\n",
    "#         s = math.ceil(v/10)//50 + 1\n",
    "#         for i in range(1,s):\n",
    "#             slices.append(i*50)\n",
    "#         last = slices[-1] + math.ceil(v/10)%50\n",
    "#         slices.append(last)\n",
    "#     return(slices)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected: 1985\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-842dfcc218a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_search_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'nytimes_meta_{k}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k, v in news_per_year.items():\n",
    "    data = []\n",
    "    start_date = f'{k}0101'\n",
    "    end_date = f'{k}1231'\n",
    "    pages = math.ceil(v/10)+1\n",
    "    for page in range(pages):\n",
    "        data.extend(parse_search_res(create_request(start_date,end_date,page)))\n",
    "        sleep(2)\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df.to_csv(f'nytimes_meta_{k}.csv')\n",
    "    print('Collected:', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
